*** IR Dump Before Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'fib.ll'
source_filename = "fib.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque

@.str = private unnamed_addr constant [3 x i8] c"%d\00", align 1
@stderr = external global %struct._IO_FILE*, align 8
@.str.1 = private unnamed_addr constant [26 x i8] c"Memory allocation failed\0A\00", align 1
@.str.2 = private unnamed_addr constant [5 x i8] c"%lf\0A\00", align 1

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}

declare i32 @__isoc99_scanf(i8* noundef, ...) #1

; Function Attrs: nounwind
declare noalias i8* @malloc(i64 noundef) #2

declare i32 @fprintf(%struct._IO_FILE* noundef, i8* noundef, ...) #1

declare i32 @printf(i8* noundef, ...) #1

; Function Attrs: nounwind
declare void @free(i8* noundef) #2

attributes #0 = { noinline nounwind optnone uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #2 = { nounwind "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #3 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!llvm.ident = !{!5}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 7, !"uwtable", i32 1}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{!"Ubuntu clang version 14.0.0-1ubuntu1.1"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.mustprogress"}
!8 = distinct !{!8, !7}
*** IR Dump After Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'fib.ll'
source_filename = "fib.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque

@.str = private unnamed_addr constant [3 x i8] c"%d\00", align 1
@stderr = external global %struct._IO_FILE*, align 8
@.str.1 = private unnamed_addr constant [26 x i8] c"Memory allocation failed\0A\00", align 1
@.str.2 = private unnamed_addr constant [5 x i8] c"%lf\0A\00", align 1

; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}

declare i32 @__isoc99_scanf(i8* noundef, ...) #1

; Function Attrs: nounwind
declare noalias i8* @malloc(i64 noundef) #2

declare i32 @fprintf(%struct._IO_FILE* noundef, i8* noundef, ...) #1

declare i32 @printf(i8* noundef, ...) #1

; Function Attrs: nounwind
declare void @free(i8* noundef) #2

attributes #0 = { noinline nounwind optnone uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #2 = { nounwind "frame-pointer"="all" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #3 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!llvm.ident = !{!5}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 7, !"uwtable", i32 1}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{!"Ubuntu clang version 14.0.0-1ubuntu1.1"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.mustprogress"}
!8 = distinct !{!8, !7}
*** IR Dump Before Expand Atomic instructions (atomic-expand) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Expand Atomic instructions (atomic-expand) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Lower AMX intrinsics (lower-amx-intrinsics) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Lower AMX intrinsics (lower-amx-intrinsics) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Lower AMX type for load/store (lower-amx-type) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Lower AMX type for load/store (lower-amx-type) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Canonicalize natural loops (loop-simplify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Canonicalize natural loops (loop-simplify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

; Loop:
52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

; Exit blocks
66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69
*** IR Dump After Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

; Loop:
52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

; Exit blocks
66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69
*** IR Dump Before Loop Strength Reduction (loop-reduce) ***
; Preheader:
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

; Loop:
52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

; Exit blocks
66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69
*** IR Dump After Loop Strength Reduction (loop-reduce) ***
; Preheader:
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

; Loop:
52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

; Exit blocks
66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69
*** IR Dump Before Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

; Loop:
26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

; Exit blocks
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52
*** IR Dump After Canonicalize Freeze Instructions in Loops (canon-freeze) ***
; Preheader:
25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

; Loop:
26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

; Exit blocks
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52
*** IR Dump Before Loop Strength Reduction (loop-reduce) ***
; Preheader:
25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

; Loop:
26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

; Exit blocks
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52
*** IR Dump After Loop Strength Reduction (loop-reduce) ***
; Preheader:
25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

; Loop:
26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

; Exit blocks
51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52
*** IR Dump Before Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Lower Garbage Collection Instructions (gc-lowering) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Lower Garbage Collection Instructions (gc-lowering) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Shadow Stack GC Lowering (shadow-stack-gc-lowering) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Shadow Stack GC Lowering (shadow-stack-gc-lowering) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Constant Hoisting (consthoist) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Constant Hoisting (consthoist) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Expand vector predication intrinsics (expandvp) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Expand vector predication intrinsics (expandvp) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Interleaved Access Pass (interleaved-access) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Interleaved Access Pass (interleaved-access) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before X86 Partial Reduction (x86-partial-reduction) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After X86 Partial Reduction (x86-partial-reduction) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Expand indirectbr instructions (indirectbr-expand) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Expand indirectbr instructions (indirectbr-expand) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before CodeGen Prepare (codegenprepare) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After CodeGen Prepare (codegenprepare) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Exception handling preparation (dwarfehprepare) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Exception handling preparation (dwarfehprepare) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump Before Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: noinline nounwind optnone uwtable
define dso_local i32 @main() #0 {
  %1 = alloca i32, align 4
  %2 = alloca i32, align 4
  %3 = alloca double*, align 8
  %4 = alloca i32, align 4
  %5 = alloca i32, align 4
  store i32 0, i32* %1, align 4
  %6 = call i32 (i8*, ...) @__isoc99_scanf(i8* noundef getelementptr inbounds ([3 x i8], [3 x i8]* @.str, i64 0, i64 0), i32* noundef %2)
  %7 = load i32, i32* %2, align 4
  %8 = sext i32 %7 to i64
  %9 = mul i64 %8, 8
  %10 = call noalias i8* @malloc(i64 noundef %9) #3
  %11 = bitcast i8* %10 to double*
  store double* %11, double** %3, align 8
  %12 = load double*, double** %3, align 8
  %13 = icmp eq double* %12, null
  br i1 %13, label %14, label %17

14:                                               ; preds = %0
  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %16 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* noundef %15, i8* noundef getelementptr inbounds ([26 x i8], [26 x i8]* @.str.1, i64 0, i64 0))
  store i32 1, i32* %1, align 4
  br label %69

17:                                               ; preds = %0
  %18 = load double*, double** %3, align 8
  %19 = getelementptr inbounds double, double* %18, i64 0
  store double 0.000000e+00, double* %19, align 8
  %20 = load i32, i32* %2, align 4
  %21 = icmp sgt i32 %20, 1
  br i1 %21, label %22, label %25

22:                                               ; preds = %17
  %23 = load double*, double** %3, align 8
  %24 = getelementptr inbounds double, double* %23, i64 1
  store double 1.000000e+00, double* %24, align 8
  br label %25

25:                                               ; preds = %22, %17
  store i32 2, i32* %4, align 4
  br label %26

26:                                               ; preds = %48, %25
  %27 = load i32, i32* %4, align 4
  %28 = load i32, i32* %2, align 4
  %29 = icmp slt i32 %27, %28
  br i1 %29, label %30, label %51

30:                                               ; preds = %26
  %31 = load double*, double** %3, align 8
  %32 = load i32, i32* %4, align 4
  %33 = sub nsw i32 %32, 1
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds double, double* %31, i64 %34
  %36 = load double, double* %35, align 8
  %37 = load double*, double** %3, align 8
  %38 = load i32, i32* %4, align 4
  %39 = sub nsw i32 %38, 2
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds double, double* %37, i64 %40
  %42 = load double, double* %41, align 8
  %43 = fadd double %36, %42
  %44 = load double*, double** %3, align 8
  %45 = load i32, i32* %4, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds double, double* %44, i64 %46
  store double %43, double* %47, align 8
  br label %48

48:                                               ; preds = %30
  %49 = load i32, i32* %4, align 4
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %4, align 4
  br label %26, !llvm.loop !6

51:                                               ; preds = %26
  store i32 0, i32* %5, align 4
  br label %52

52:                                               ; preds = %63, %51
  %53 = load i32, i32* %5, align 4
  %54 = load i32, i32* %2, align 4
  %55 = icmp slt i32 %53, %54
  br i1 %55, label %56, label %66

56:                                               ; preds = %52
  %57 = load double*, double** %3, align 8
  %58 = load i32, i32* %5, align 4
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds double, double* %57, i64 %59
  %61 = load double, double* %60, align 8
  %62 = call i32 (i8*, ...) @printf(i8* noundef getelementptr inbounds ([5 x i8], [5 x i8]* @.str.2, i64 0, i64 0), double noundef %61)
  br label %63

63:                                               ; preds = %56
  %64 = load i32, i32* %5, align 4
  %65 = add nsw i32 %64, 1
  store i32 %65, i32* %5, align 4
  br label %52, !llvm.loop !8

66:                                               ; preds = %52
  %67 = load double*, double** %3, align 8
  %68 = bitcast double* %67 to i8*
  call void @free(i8* noundef %68) #3
  store i32 0, i32* %1, align 4
  br label %69

69:                                               ; preds = %66, %14
  %70 = load i32, i32* %1, align 4
  ret i32 %70
}
# *** IR Dump Before X86 DAG->DAG Instruction Selection (amdgpu-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness

# End machine code for function main.

# *** IR Dump After X86 DAG->DAG Instruction Selection (amdgpu-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Domain Reassignment Pass (x86-domain-reassignment) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Domain Reassignment Pass (x86-domain-reassignment) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Early Tail Duplication (early-tailduplication) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Early Tail Duplication (early-tailduplication) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Slot index numbering (slotindexes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  %12:gr32 = COPY $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
208B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
224B	  $rdi = COPY %7:gr64
240B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
256B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
272B	  %5:gr64 = COPY $rax
288B	  %3:gr64 = COPY %5:gr64
304B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
320B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
336B	  JCC_1 %bb.2, 5, implicit $eflags

352B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

368B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
384B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
400B	  %74:gr64 = MOV64ri @.str.1
416B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
432B	  $rdi = COPY %78:gr64
448B	  $rsi = COPY %74:gr64
464B	  $al = MOV8ri 0
480B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
496B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
512B	  %75:gr32 = COPY $eax
528B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
544B	  JMP_1 %bb.13

560B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

576B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
592B	  %15:fr64 = FsFLD0SD
608B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
624B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
640B	  JCC_1 %bb.4, 14, implicit $eflags

656B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

672B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
688B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
704B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

720B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

736B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

752B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

768B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
784B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
800B	  JCC_1 %bb.8, 13, implicit $eflags

816B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

832B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
848B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
864B	  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
880B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
896B	  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
912B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
928B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
944B	  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
960B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
976B	  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
992B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1008B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1024B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1040B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1056B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1072B	  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
1088B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1104B	  JMP_1 %bb.5

1120B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1136B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1152B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1168B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1184B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1200B	  JCC_1 %bb.12, 13, implicit $eflags

1216B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1232B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1248B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1280B	  %30:gr64 = MOV64ri @.str.2
1296B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1312B	  $rdi = COPY %30:gr64
1328B	  $xmm0 = COPY %35:fr64
1344B	  $al = MOV8ri 1
1360B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1376B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  %32:gr32 = COPY $eax

1408B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1424B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1440B	  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
1456B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1472B	  JMP_1 %bb.9

1488B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1504B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1520B	  %28:gr64 = COPY %29:gr64
1536B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1552B	  $rdi = COPY %28:gr64
1568B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1584B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1600B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1616B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1632B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1648B	  $eax = COPY %80:gr32
1664B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  %12:gr32 = COPY $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
208B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
224B	  $rdi = COPY %7:gr64
240B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
256B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
272B	  %5:gr64 = COPY $rax
288B	  %3:gr64 = COPY %5:gr64
304B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
320B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
336B	  JCC_1 %bb.2, 5, implicit $eflags

352B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

368B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
384B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
400B	  %74:gr64 = MOV64ri @.str.1
416B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
432B	  $rdi = COPY %78:gr64
448B	  $rsi = COPY %74:gr64
464B	  $al = MOV8ri 0
480B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
496B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
512B	  %75:gr32 = COPY $eax
528B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
544B	  JMP_1 %bb.13

560B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

576B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
592B	  %15:fr64 = FsFLD0SD
608B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
624B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
640B	  JCC_1 %bb.4, 14, implicit $eflags

656B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

672B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
688B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
704B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

720B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

736B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

752B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

768B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
784B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
800B	  JCC_1 %bb.8, 13, implicit $eflags

816B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

832B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
848B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
864B	  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
880B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
896B	  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
912B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
928B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
944B	  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
960B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
976B	  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
992B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1008B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1024B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1040B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1056B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1072B	  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
1088B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1104B	  JMP_1 %bb.5

1120B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1136B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1152B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1168B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1184B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1200B	  JCC_1 %bb.12, 13, implicit $eflags

1216B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1232B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1248B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1280B	  %30:gr64 = MOV64ri @.str.2
1296B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1312B	  $rdi = COPY %30:gr64
1328B	  $xmm0 = COPY %35:fr64
1344B	  $al = MOV8ri 1
1360B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1376B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  %32:gr32 = COPY $eax

1408B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1424B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1440B	  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
1456B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1472B	  JMP_1 %bb.9

1488B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1504B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1520B	  %28:gr64 = COPY %29:gr64
1536B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1552B	  $rdi = COPY %28:gr64
1568B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1584B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1600B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1616B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1632B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1648B	  $eax = COPY %80:gr32
1664B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Early If-Conversion (early-ifcvt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Early If-Conversion (early-ifcvt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine InstCombiner (machine-combiner) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine InstCombiner (machine-combiner) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 cmov Conversion (x86-cmov-conversion) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 cmov Conversion (x86-cmov-conversion) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine code sinking (machine-sink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine code sinking (machine-sink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Peephole Optimizations (peephole-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Peephole Optimizations (peephole-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Live Range Shrink (lrshrink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Live Range Shrink (lrshrink) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Fixup SetCC (x86-fixup-setcc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Fixup SetCC (x86-fixup-setcc) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 LEA Optimize (x86-optimize-LEAs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 LEA Optimize (x86-optimize-LEAs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Optimize Call Frame (x86-cf-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Optimize Call Frame (x86-cf-opt) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Avoid Store Forwarding Blocks (x86-avoid-SFB) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Avoid Store Forwarding Blocks (x86-avoid-SFB) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 speculative load hardening (x86-slh) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 speculative load hardening (x86-slh) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 EFLAGS copy lowering (x86-flags-copy-lowering) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 EFLAGS copy lowering (x86-flags-copy-lowering) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Detect Dead Lanes (detect-dead-lanes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Detect Dead Lanes (detect-dead-lanes) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Process Implicit Definitions (processimpdefs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Process Implicit Definitions (processimpdefs) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Live Variable Analysis (livevars) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %10:gr64
  $rsi = COPY %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %12:gr32 = COPY $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri %9:gr64(tied-def 0), 3, implicit-def $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY $rax
  %3:gr64 = COPY %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %78:gr64
  $rsi = COPY %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %75:gr32 = COPY $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 %67:gr32(tied-def 0), 1, implicit-def $eflags
  %64:gr64_nosp = MOVSX64rr32 %66:gr32
  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 %58:gr32(tied-def 0), 2, implicit-def $eflags
  %55:gr64_nosp = MOVSX64rr32 %57:gr32
  %51:fr64 = ADDSDrm %62:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 %72:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %30:gr64
  $xmm0 = COPY %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %32:gr32 = COPY $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 %42:gr32(tied-def 0), 1, implicit-def $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY %80:gr32
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Live Variable Analysis (livevars) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri killed %9:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 killed %67:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 killed %58:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = ADDSDrm killed %62:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 killed %72:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 killed %42:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function main: IsSSA, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri killed %9:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 killed %67:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 killed %58:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = ADDSDrm killed %62:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 killed %72:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 killed %42:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function main: NoPHIs, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri killed %9:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 killed %67:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 killed %58:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = ADDSDrm killed %62:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 killed %72:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 killed %42:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function main: NoPHIs, TracksLiveness
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = SHL64ri killed %9:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = SUB32ri8 killed %67:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = SUB32ri8 killed %58:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = ADDSDrm killed %62:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = ADD32ri8 killed %72:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = ADD32ri8 killed %42:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = COPY killed %9:gr64
  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = COPY killed %67:gr32
  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = COPY killed %58:gr32
  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = COPY killed %62:fr64
  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = COPY killed %72:gr32
  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = COPY killed %42:gr32
  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Slot index numbering (slotindexes) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  %10:gr64 = MOV64ri @.str
  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %10:gr64
  $rsi = COPY killed %11:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %12:gr32 = COPY killed $eax
  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  %7:gr64 = COPY killed %9:gr64
  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %7:gr64
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  %5:gr64 = COPY killed $rax
  %3:gr64 = COPY killed %5:gr64
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  %74:gr64 = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %78:gr64
  $rsi = COPY killed %74:gr64
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %75:gr32 = COPY killed $eax
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %15:fr64 = FsFLD0SD
  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %66:gr32 = COPY killed %67:gr32
  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %57:gr32 = COPY killed %58:gr32
  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
  %51:fr64 = COPY killed %62:fr64
  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  %71:gr32 = COPY killed %72:gr32
  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
  %30:gr64 = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %30:gr64
  $xmm0 = COPY killed %35:fr64
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  dead %32:gr32 = COPY killed $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  %41:gr32 = COPY killed %42:gr32
  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  %28:gr64 = COPY killed %29:gr64
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $rdi = COPY killed %28:gr64
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  $eax = COPY killed %80:gr32
  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY killed %10:gr64
96B	  $rsi = COPY killed %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = COPY killed %9:gr64
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY killed %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %5:gr64 = COPY killed $rax
304B	  %3:gr64 = COPY killed %5:gr64
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY killed %78:gr64
464B	  $rsi = COPY killed %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
880B	  %66:gr32 = COPY killed %67:gr32
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
928B	  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
976B	  %57:gr32 = COPY killed %58:gr32
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
1024B	  %51:fr64 = COPY killed %62:fr64
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1136B	  %71:gr32 = COPY killed %72:gr32
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY killed %30:gr64
1408B	  $xmm0 = COPY killed %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1520B	  %41:gr32 = COPY killed %42:gr32
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1616B	  %28:gr64 = COPY killed %29:gr64
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY killed %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY killed %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Live Interval Analysis (liveintervals) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY killed %10:gr64
96B	  $rsi = COPY killed %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = COPY killed %9:gr64
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY killed %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %5:gr64 = COPY killed $rax
304B	  %3:gr64 = COPY killed %5:gr64
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm killed %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY killed %78:gr64
464B	  $rsi = COPY killed %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr killed %16:gr64, 1, $noreg, 0, $noreg, killed %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed %19:gr64, 1, $noreg, 8, $noreg, killed %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
880B	  %66:gr32 = COPY killed %67:gr32
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 killed %66:gr32
928B	  %62:fr64 = MOVSDrm_alt killed %68:gr64, 8, killed %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
976B	  %57:gr32 = COPY killed %58:gr32
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 killed %57:gr32
1024B	  %51:fr64 = COPY killed %62:fr64
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), killed %59:gr64, 8, killed %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed %48:gr64, 8, killed %47:gr64_nosp, 0, $noreg, killed %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1136B	  %71:gr32 = COPY killed %72:gr32
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt killed %38:gr64, 8, killed %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY killed %30:gr64
1408B	  $xmm0 = COPY killed %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1520B	  %41:gr32 = COPY killed %42:gr32
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1616B	  %28:gr64 = COPY killed %29:gr64
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY killed %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY killed %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Live Interval Analysis (liveintervals) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = COPY %9:gr64
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %5:gr64 = COPY killed $rax
304B	  %3:gr64 = COPY %5:gr64
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
880B	  %66:gr32 = COPY %67:gr32
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
976B	  %57:gr32 = COPY %58:gr32
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1024B	  %51:fr64 = COPY %62:fr64
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1136B	  %71:gr32 = COPY %72:gr32
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1520B	  %41:gr32 = COPY %42:gr32
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1616B	  %28:gr64 = COPY %29:gr64
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Simple Register Coalescing (simple-register-coalescing) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %9:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
192B	  %7:gr64 = COPY %9:gr64
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %5:gr64 = COPY killed $rax
304B	  %3:gr64 = COPY %5:gr64
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %67:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
880B	  %66:gr32 = COPY %67:gr32
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %62:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %58:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
976B	  %57:gr32 = COPY %58:gr32
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1024B	  %51:fr64 = COPY %62:fr64
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %72:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1136B	  %71:gr32 = COPY %72:gr32
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %42:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1520B	  %41:gr32 = COPY %42:gr32
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %29:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1616B	  %28:gr64 = COPY %29:gr64
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Simple Register Coalescing (simple-register-coalescing) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Rename Disconnected Subregister Components (rename-independent-subregs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Rename Disconnected Subregister Components (rename-independent-subregs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Debug Variable Analysis (livedebugvars) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Debug Variable Analysis (livedebugvars) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Live Stack Slot Analysis (livestacks) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Live Stack Slot Analysis (livestacks) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Virtual Register Map (virtregmap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Virtual Register Map (virtregmap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Live Register Matrix (liveregmatrix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Live Register Matrix (liveregmatrix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump Before Greedy Register Allocator (greedy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY killed $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY killed $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY killed $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $al, implicit killed $rdi, implicit killed $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY killed $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit killed $eax

# End machine code for function main.

# *** IR Dump After Greedy Register Allocator (greedy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Tile Register Configure (tileconfig) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Tile Register Configure (tileconfig) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  %10:gr64 = MOV64ri @.str
48B	  %11:gr64 = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
80B	  $rdi = COPY %10:gr64
96B	  $rsi = COPY %11:gr64
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
160B	  dead %12:gr32 = COPY $eax
176B	  %7:gr64 = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  %7:gr64 = SHL64ri %7:gr64(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
240B	  $rdi = COPY %7:gr64
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
288B	  %3:gr64 = COPY $rax
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, %3:gr64 :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  %77:gr64 = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  %78:gr64 = MOV64rm %77:gr64, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  %74:gr64 = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
448B	  $rdi = COPY %78:gr64
464B	  $rsi = COPY %74:gr64
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
528B	  dead %75:gr32 = COPY $eax
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  %16:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  %15:fr64 = FsFLD0SD
624B	  MOVSDmr %16:gr64, 1, $noreg, 0, $noreg, %15:fr64 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  %19:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  %18:fr64 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr %19:gr64, 1, $noreg, 8, $noreg, %18:fr64 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  %22:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm %22:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  %68:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  %66:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  %66:gr32 = SUB32ri8 %66:gr32(tied-def 0), 1, implicit-def dead $eflags
912B	  %64:gr64_nosp = MOVSX64rr32 %66:gr32
928B	  %51:fr64 = MOVSDrm_alt %68:gr64, 8, %64:gr64_nosp, 0, $noreg :: (load (s64) from %ir.35)
944B	  %59:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  %57:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  %57:gr32 = SUB32ri8 %57:gr32(tied-def 0), 2, implicit-def dead $eflags
1008B	  %55:gr64_nosp = MOVSX64rr32 %57:gr32
1040B	  %51:fr64 = ADDSDrm %51:fr64(tied-def 0), %59:gr64, 8, %55:gr64_nosp, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  %48:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  %47:gr64_nosp = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr %48:gr64, 8, %47:gr64_nosp, 0, $noreg, %51:fr64 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  %71:gr32 = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  %71:gr32 = ADD32ri8 %71:gr32(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, %71:gr32 :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  %25:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm %25:gr32, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  %38:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  %37:gr64_nosp = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  %35:fr64 = MOVSDrm_alt %38:gr64, 8, %37:gr64_nosp, 0, $noreg :: (load (s64) from %ir.60)
1360B	  %30:gr64 = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1392B	  $rdi = COPY %30:gr64
1408B	  $xmm0 = COPY %35:fr64
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1472B	  dead %32:gr32 = COPY $eax

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  %41:gr32 = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  %41:gr32 = ADD32ri8 %41:gr32(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, %41:gr32 :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  %28:gr64 = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1648B	  $rdi = COPY %28:gr64
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  %80:gr32 = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1744B	  $eax = COPY %80:gr32
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Register Allocation Pass Scoring (regallocscoringpass) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Register Allocation Pass Scoring (regallocscoringpass) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

0B	bb.0 (%ir-block.0):
	  successors: %bb.2, %bb.1

16B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
32B	  renamable $rdi = MOV64ri @.str
48B	  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
64B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
112B	  $al = MOV8ri 0
128B	  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
144B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
176B	  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
208B	  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
224B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
256B	  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
272B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
320B	  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
336B	  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
352B	  JCC_1 %bb.2, 5, implicit killed $eflags

368B	bb.1 (%ir-block.14):
	; predecessors: %bb.0
	  successors: %bb.13

384B	  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
400B	  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
416B	  renamable $rsi = MOV64ri @.str.1
432B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
480B	  $al = MOV8ri 0
496B	  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
512B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
544B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
560B	  JMP_1 %bb.13

576B	bb.2 (%ir-block.17):
	; predecessors: %bb.0
	  successors: %bb.4, %bb.3

592B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
608B	  renamable $xmm0 = FsFLD0SD
624B	  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
640B	  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
656B	  JCC_1 %bb.4, 14, implicit killed $eflags

672B	bb.3 (%ir-block.22):
	; predecessors: %bb.2
	  successors: %bb.4

688B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
704B	  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
720B	  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

736B	bb.4 (%ir-block.25):
	; predecessors: %bb.2, %bb.3
	  successors: %bb.5

752B	  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

768B	bb.5 (%ir-block.26):
	; predecessors: %bb.4, %bb.7
	  successors: %bb.8, %bb.6

784B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
800B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
816B	  JCC_1 %bb.8, 13, implicit killed $eflags

832B	bb.6 (%ir-block.30):
	; predecessors: %bb.5
	  successors: %bb.7

848B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
864B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
896B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
912B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
928B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
944B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
960B	  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
992B	  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
1008B	  renamable $rcx = MOVSX64rr32 killed renamable $ecx
1040B	  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
1056B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1072B	  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1088B	  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

1104B	bb.7 (%ir-block.48):
	; predecessors: %bb.6
	  successors: %bb.5

1120B	  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
1152B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1168B	  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
1184B	  JMP_1 %bb.5

1200B	bb.8 (%ir-block.51):
	; predecessors: %bb.5
	  successors: %bb.9

1216B	  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

1232B	bb.9 (%ir-block.52):
	; predecessors: %bb.8, %bb.11
	  successors: %bb.12, %bb.10

1248B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1264B	  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
1280B	  JCC_1 %bb.12, 13, implicit killed $eflags

1296B	bb.10 (%ir-block.56):
	; predecessors: %bb.9
	  successors: %bb.11

1312B	  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1328B	  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1344B	  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
1360B	  renamable $rdi = MOV64ri @.str.2
1376B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1424B	  $al = MOV8ri 1
1440B	  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
1456B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

1488B	bb.11 (%ir-block.63):
	; predecessors: %bb.10
	  successors: %bb.9

1504B	  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
1536B	  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
1552B	  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
1568B	  JMP_1 %bb.9

1584B	bb.12 (%ir-block.66):
	; predecessors: %bb.9
	  successors: %bb.13

1600B	  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
1632B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1664B	  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
1680B	  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
1696B	  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

1712B	bb.13 (%ir-block.69):
	; predecessors: %bb.12, %bb.1

1728B	  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
1760B	  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine Loop Invariant Code Motion (machinelicm) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine Loop Invariant Code Motion (machinelicm) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Lower Tile Copy (lowertilecopy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Lower Tile Copy (lowertilecopy) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 FP Stackifier (x86-codegen) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 FP Stackifier (x86-codegen) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Load Value Injection (LVI) Load Hardening (x86-lvi-load) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Load Value Injection (LVI) Load Hardening (x86-lvi-load) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before PostRA Machine Sink (postra-machine-sink) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After PostRA Machine Sink (postra-machine-sink) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Shrink Wrapping analysis (shrink-wrap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Shrink Wrapping analysis (shrink-wrap) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Prologue/Epilogue Insertion & Frame Finalization (prologepilog) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#0: size=4, align=4, at location [SP+8]
  fi#1: size=4, align=4, at location [SP+8]
  fi#2: size=8, align=8, at location [SP+8]
  fi#3: size=4, align=4, at location [SP+8]
  fi#4: size=4, align=4, at location [SP+8]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r %stack.1, 1, $noreg, 0, $noreg
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  renamable $rdi = MOVSX64rm32 %stack.1, 1, $noreg, 0, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV64mr %stack.2, 1, $noreg, 0, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 %stack.2, 1, $noreg, 0, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 %stack.1, 1, $noreg, 0, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi %stack.3, 1, $noreg, 0, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm %stack.3, 1, $noreg, 0, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.3, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi %stack.4, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, %stack.1, 1, $noreg, 0, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm %stack.4, 1, $noreg, 0, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr %stack.4, 1, $noreg, 0, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm %stack.2, 1, $noreg, 0, $noreg :: (load (s64) from %ir.3)
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  ADJCALLSTACKUP64 0, 0, implicit-def $rsp, implicit-def dead $eflags, implicit-def $ssp, implicit $rsp, implicit $ssp
  MOV32mi %stack.0, 1, $noreg, 0, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm %stack.0, 1, $noreg, 0, $noreg :: (load (s32) from %ir.1)
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Prologue/Epilogue Insertion & Frame Finalization (prologepilog) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Control Flow Optimizer (branch-folder) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Control Flow Optimizer (branch-folder) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Tail Duplication (tailduplication) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Tail Duplication (tailduplication) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = FsFLD0SD
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 pseudo instruction expansion pass (x86-pseudo) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 pseudo instruction expansion pass (x86-pseudo) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Post RA top-down list latency scheduler (post-RA-sched) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Post RA top-down list latency scheduler (post-RA-sched) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Analyze Machine Code For Garbage Collection (gc-analysis) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Analyze Machine Code For Garbage Collection (gc-analysis) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Insert fentry calls (fentry-insert) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Insert fentry calls (fentry-insert) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Insert XRay ops (xray-instrumentation) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Insert XRay ops (xray-instrumentation) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Implement the 'patchable-function' attribute (patchable-function) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Implement the 'patchable-function' attribute (patchable-function) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Execution Dependency Fix (x86-execution-domain-fix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Execution Dependency Fix (x86-execution-domain-fix) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before BreakFalseDeps (break-false-deps) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After BreakFalseDeps (break-false-deps) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Byte/Word Instruction Fixup (x86-fixup-bw-insts) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Byte/Word Instruction Fixup (x86-fixup-bw-insts) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 LEA Fixup (x86-fixup-LEAs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 LEA Fixup (x86-fixup-LEAs) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Compressing EVEX instrs to VEX encoding when possible (x86-evex-to-vex-compress) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Compressing EVEX instrs to VEX encoding when possible (x86-evex-to-vex-compress) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Contiguously Lay Out Funclets (funclet-layout) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Contiguously Lay Out Funclets (funclet-layout) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before StackMap Liveness Analysis (stackmap-liveness) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After StackMap Liveness Analysis (stackmap-liveness) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Live DEBUG_VALUE analysis (livedebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Live DEBUG_VALUE analysis (livedebugvalues) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Speculative Execution Side Effect Suppression (x86-seses) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Speculative Execution Side Effect Suppression (x86-seses) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Check CFA info and insert CFI instructions if needed (cfi-instr-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Check CFA info and insert CFI instructions if needed (cfi-instr-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before X86 Load Value Injection (LVI) Ret-Hardening (x86-lvi-ret) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After X86 Load Value Injection (LVI) Ret-Hardening (x86-lvi-ret) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump Before Pseudo Probe Inserter (pseudo-probe-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

# *** IR Dump After Pseudo Probe Inserter (pseudo-probe-inserter) ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Frame Objects:
  fi#-1: size=8, align=16, fixed, at location [SP-8]
  fi#0: size=4, align=4, at location [SP-36]
  fi#1: size=4, align=4, at location [SP-20]
  fi#2: size=8, align=8, at location [SP-32]
  fi#3: size=4, align=4, at location [SP-12]
  fi#4: size=4, align=4, at location [SP-16]
Constant Pool:
  cp#0: 1.000000e+00, align=8

bb.0 (%ir-block.0):
  successors: %bb.2, %bb.1

  frame-setup PUSH64r killed $rbp, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  CFI_INSTRUCTION offset $rbp, -16
  $rbp = frame-setup MOV64rr $rsp
  CFI_INSTRUCTION def_cfa_register $rbp
  $rsp = frame-setup SUB64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)
  renamable $rdi = MOV64ri @.str
  renamable $rsi = LEA64r $rbp, 1, $noreg, -12, $noreg
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @__isoc99_scanf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  renamable $rdi = MOVSX64rm32 $rbp, 1, $noreg, -12, $noreg :: (load (s32) from %ir.2)
  renamable $rdi = SHL64ri killed renamable $rdi(tied-def 0), 3, implicit-def dead $eflags
  CALL64pcrel32 target-flags(x86-plt) @malloc, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi, implicit-def $rax
  MOV64mr $rbp, 1, $noreg, -24, $noreg, killed renamable $rax :: (store (s64) into %ir.3)
  CMP64mi8 $rbp, 1, $noreg, -24, $noreg, 0, implicit-def $eflags :: (load (s64) from %ir.3)
  JCC_1 %bb.2, 5, implicit killed $eflags

bb.1 (%ir-block.14):
; predecessors: %bb.0
  successors: %bb.13

  renamable $rax = MOV64rm $rip, 1, $noreg, target-flags(x86-gotpcrel) @stderr, $noreg
  renamable $rdi = MOV64rm killed renamable $rax, 1, $noreg, 0, $noreg :: (load (s64) from @stderr)
  renamable $rsi = MOV64ri @.str.1
  $al = MOV8ri 0
  CALL64pcrel32 target-flags(x86-plt) @fprintf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $rsi, implicit-def $eax
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 1 :: (store (s32) into %ir.1)
  JMP_1 %bb.13

bb.2 (%ir-block.17):
; predecessors: %bb.0
  successors: %bb.4, %bb.3

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = XORPSrr undef $xmm0(tied-def 0), undef $xmm0
  MOVSDmr killed renamable $rax, 1, $noreg, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.19)
  CMP32mi8 $rbp, 1, $noreg, -12, $noreg, 1, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.4, 14, implicit killed $eflags

bb.3 (%ir-block.22):
; predecessors: %bb.2
  successors: %bb.4

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $xmm0 = MOVSDrm_alt $rip, 1, $noreg, %const.0, $noreg
  MOVSDmr killed renamable $rax, 1, $noreg, 8, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.24)

bb.4 (%ir-block.25):
; predecessors: %bb.2, %bb.3
  successors: %bb.5

  MOV32mi $rbp, 1, $noreg, -4, $noreg, 2 :: (store (s32) into %ir.4)

bb.5 (%ir-block.26):
; predecessors: %bb.4, %bb.7
  successors: %bb.8, %bb.6

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.8, 13, implicit killed $eflags

bb.6 (%ir-block.30):
; predecessors: %bb.5
  successors: %bb.7

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 1, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.35)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $ecx = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $ecx = SUB32ri8 killed renamable $ecx(tied-def 0), 2, implicit-def dead $eflags
  renamable $rcx = MOVSX64rr32 killed renamable $ecx
  renamable $xmm0 = ADDSDrm killed renamable $xmm0(tied-def 0), killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, implicit $mxcsr :: (load (s64) from %ir.41)
  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  MOVSDmr killed renamable $rax, 8, killed renamable $rcx, 0, $noreg, killed renamable $xmm0 :: (store (s64) into %ir.47)

bb.7 (%ir-block.48):
; predecessors: %bb.6
  successors: %bb.5

  renamable $eax = MOV32rm $rbp, 1, $noreg, -4, $noreg :: (load (s32) from %ir.4)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -4, $noreg, killed renamable $eax :: (store (s32) into %ir.4)
  JMP_1 %bb.5

bb.8 (%ir-block.51):
; predecessors: %bb.5
  successors: %bb.9

  MOV32mi $rbp, 1, $noreg, -8, $noreg, 0 :: (store (s32) into %ir.5)

bb.9 (%ir-block.52):
; predecessors: %bb.8, %bb.11
  successors: %bb.12, %bb.10

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  CMP32rm killed renamable $eax, $rbp, 1, $noreg, -12, $noreg, implicit-def $eflags :: (load (s32) from %ir.2)
  JCC_1 %bb.12, 13, implicit killed $eflags

bb.10 (%ir-block.56):
; predecessors: %bb.9
  successors: %bb.11

  renamable $rax = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  renamable $rcx = MOVSX64rm32 $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $xmm0 = MOVSDrm_alt killed renamable $rax, 8, killed renamable $rcx, 0, $noreg :: (load (s64) from %ir.60)
  renamable $rdi = MOV64ri @.str.2
  $al = MOV8ri 1
  CALL64pcrel32 target-flags(x86-plt) @printf, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $al, implicit $rdi, implicit $xmm0, implicit-def $eax

bb.11 (%ir-block.63):
; predecessors: %bb.10
  successors: %bb.9

  renamable $eax = MOV32rm $rbp, 1, $noreg, -8, $noreg :: (load (s32) from %ir.5)
  renamable $eax = ADD32ri8 killed renamable $eax(tied-def 0), 1, implicit-def dead $eflags
  MOV32mr $rbp, 1, $noreg, -8, $noreg, killed renamable $eax :: (store (s32) into %ir.5)
  JMP_1 %bb.9

bb.12 (%ir-block.66):
; predecessors: %bb.9
  successors: %bb.13

  renamable $rdi = MOV64rm $rbp, 1, $noreg, -24, $noreg :: (load (s64) from %ir.3)
  CALL64pcrel32 target-flags(x86-plt) @free, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $rdi
  MOV32mi $rbp, 1, $noreg, -28, $noreg, 0 :: (store (s32) into %ir.1)

bb.13 (%ir-block.69):
; predecessors: %bb.12, %bb.1

  renamable $eax = MOV32rm $rbp, 1, $noreg, -28, $noreg :: (load (s32) from %ir.1)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 32, implicit-def dead $eflags
  $rbp = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa $rsp, 8
  RET64 implicit $eax

# End machine code for function main.

